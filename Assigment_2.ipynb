{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Roberto Alvarez & Marcos Crespo"
      ],
      "metadata": {
        "id": "OCTVmGzgzkCh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We first import the file and create the Pandas' Dataframe:"
      ],
      "metadata": {
        "id": "m7f4QEpa053N"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SfNd15jZFC0D",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c970697a-9df1-4ab1-d8a9-f070e59a7530"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "id": "9rMuzopWfvUG",
        "outputId": "887cf66b-b8de-4cb7-d7cc-74da1ac69942"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-6bab2b97-f775-4c31-9b6f-2f3d72c8d128\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-6bab2b97-f775-4c31-9b6f-2f3d72c8d128\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving wind_available.csv.gzip to wind_available.csv.gzip\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "df = pd.read_csv('wind_available.csv.gzip', compression=\"gzip\")"
      ],
      "metadata": {
        "id": "MzFnmejKfDmk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Relevant information and additional documents\n",
        "\n",
        "Prior to the document developmentm, we wanted to point out that the main original (in the sense that it is not only what its been asked in the document) step we have made is in relation to the dates.\n",
        "\n",
        "He have combined all the date-related features of our data into one date-datatype column, which exists in pandas. This way, we could made a clear cut in the time-series of our data in order to make the predictions for a non iid data. Since we were not asked to make any time-series model, we the deleted this feature and worked only with the timeless data.\n",
        "\n",
        "The main reason we had to do this was that the competition data we observed was in 2010, and our data only covered 2009. The standard procedure when doing this is to create the train-test partitions with a time-threshold, not shuffling the data.\n",
        "\n",
        "Please find attached in the .zip file the aditional document required for this assigment, commenting the main use cases we have found to ChatGPT."
      ],
      "metadata": {
        "id": "73YC_Y3l0Gz7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. EDA"
      ],
      "metadata": {
        "id": "p3Mv7I08zz3B"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "First step is to create a simple Exploratory Data Analysis in order to have a brief understanding of quality, quantity and general characteristics of the data."
      ],
      "metadata": {
        "id": "hgYLhvVr8wUx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Checking the number of instances (rows) and attributes (columns)\n",
        "num_instances, num_attributes = df.shape\n",
        "print(\"Number of instances (rows):\", num_instances)\n",
        "print(\"Number of attributes (columns):\", num_attributes)\n",
        "\n",
        "# Display data type information for each column\n",
        "print(df.dtypes)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hh1Bm4QTnYlh",
        "outputId": "3fb4f8ef-9960-4d62-c26f-0830564e5e5b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of instances (rows): 4748\n",
            "Number of attributes (columns): 555\n",
            "energy     float64\n",
            "year         int64\n",
            "month        int64\n",
            "day          int64\n",
            "hour         int64\n",
            "            ...   \n",
            "v100.21    float64\n",
            "v100.22    float64\n",
            "v100.23    float64\n",
            "v100.24    float64\n",
            "v100.25    float64\n",
            "Length: 555, dtype: object\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Typically, columns with data type object or category represent categorical variables, while columns with data types such as int64 or float64 represent numerical variables. We have 4748 instances (rows) and 555 attributes (columns) in our dataset. The 'energy' column, our target variable, it's of type 'float64' this represents the output in a regression problem. Other columns, such as 'year', 'month', 'day', 'hour', and several others, seem to contain numerical data as well, represented by 'int64' or 'float64' data types."
      ],
      "metadata": {
        "id": "mwIjYrIg0J11"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "No categorical or character columns are observed in this data."
      ],
      "metadata": {
        "id": "n5pKJx7M9gpf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Missing values\n",
        "\n",
        "#Calculate the percentage of missing values for each column\n",
        "missing_percentage = (df.isnull().sum() / len(df)) * 100\n",
        "\n",
        "# Sort columns by their missing percentage in descending order\n",
        "missing_percentage = missing_percentage.sort_values(ascending=False)\n",
        "\n",
        "# Display the result\n",
        "print(missing_percentage)\n"
      ],
      "metadata": {
        "id": "o1ZFvbRRhHIM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "43a82e2e-fde1-4be8-944b-7013743f5b9b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "lai_hv.13    20.303286\n",
            "fsr.3        20.155855\n",
            "v10n.24      19.945240\n",
            "stl3.20      19.924179\n",
            "lai_hv.19    19.839933\n",
            "               ...    \n",
            "hour          0.000000\n",
            "year          0.000000\n",
            "day           0.000000\n",
            "month         0.000000\n",
            "energy        0.000000\n",
            "Length: 555, dtype: float64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We have several variables with missing values, to handle it we will impute them with the median"
      ],
      "metadata": {
        "id": "Mu5riOi10VFI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Imputation\n",
        "# Select numerical columns\n",
        "numeric_columns = df.select_dtypes(include=['float64', 'int64']).columns\n",
        "\n",
        "# Impute missing values with the median for numerical columns\n",
        "for column in numeric_columns:\n",
        "    median_value = df[column].median()\n",
        "    df[column].fillna(median_value, inplace=True)\n"
      ],
      "metadata": {
        "id": "Pi0UgaPLwgZA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check for missing values after imputation\n",
        "missing_after_imputation = df.isnull().sum()\n",
        "print(\"Missing values after imputation:\")\n",
        "print(missing_after_imputation)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h2awR4Zywoww",
        "outputId": "99da9d0c-fcf6-48d2-b9e8-4d757fed05ba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Missing values after imputation:\n",
            "energy     0\n",
            "year       0\n",
            "month      0\n",
            "day        0\n",
            "hour       0\n",
            "          ..\n",
            "v100.21    0\n",
            "v100.22    0\n",
            "v100.23    0\n",
            "v100.24    0\n",
            "v100.25    0\n",
            "Length: 555, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we dont have missing values"
      ],
      "metadata": {
        "id": "Nm0c4O1b0oPW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check for constant columns\n",
        "constant_columns = [col for col in df.columns if df[col].nunique() == 1]\n",
        "\n",
        "# Display constant columns\n",
        "print(\"Constant columns:\")\n",
        "print(constant_columns)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1SSjCFJdyE21",
        "outputId": "4ca5eb13-8932-485d-ff79-15d43437e5bc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Constant columns:\n",
            "[]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this dataset there are not constant columns"
      ],
      "metadata": {
        "id": "JLYBY5zZ0s8I"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. Split Data"
      ],
      "metadata": {
        "id": "PfnDTMuQr4cx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check unique values and their counts in the 'year' column\n",
        "year_counts = df['year'].value_counts().sort_index()\n",
        "\n",
        "# Display the unique values and their counts\n",
        "print(\"Unique values and their counts in the 'year' column:\")\n",
        "print(year_counts)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k-_NxVB6T5gJ",
        "outputId": "e040956d-a99d-4f77-c5b2-b8df1a037c5e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unique values and their counts in the 'year' column:\n",
            "2005    1256\n",
            "2006    1272\n",
            "2007    1121\n",
            "2008     178\n",
            "2009     921\n",
            "Name: year, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data is not iid, it follows a temporal order, we will bear that in mind to split the data, since our goal is to forecast future energy production, the test set will contain data from the most recent time periods to simulate real-world predictions."
      ],
      "metadata": {
        "id": "ZIw8YqSjV4AZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 'df' has columns 'year', 'month', 'day', and 'hour'\n",
        "# Make sure the columns have the correct type (integer) before combining them\n",
        "\n",
        "df['datetime'] = pd.to_datetime(df[['year', 'month', 'day', 'hour']])\n",
        "\n",
        "# Now, you can delete the original columns if you wish\n",
        "df = df.drop(['year', 'month', 'day', 'hour'], axis=1)\n",
        "\n",
        "# Visualize the resulting DataFrame\n",
        "print(df.head())\n",
        "\n"
      ],
      "metadata": {
        "id": "KvrkLF6I5M40",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3a04c069-6915-40a7-d88b-bc7316fc4153"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    energy     p54.162.1     p54.162.2     p54.162.3     p54.162.4  \\\n",
            "0   402.71  2.534970e+06  2.526864e+06  2.518754e+06  2.510648e+06   \n",
            "1   696.80  2.513508e+06  2.505370e+06  2.521184e+06  2.513088e+06   \n",
            "2  1591.15  2.533727e+06  2.525703e+06  2.517678e+06  2.509654e+06   \n",
            "3  1338.62  2.513508e+06  2.526548e+06  2.518609e+06  2.510670e+06   \n",
            "4   562.50  2.529543e+06  2.505370e+06  2.513702e+06  2.505782e+06   \n",
            "\n",
            "      p54.162.5     p54.162.6     p54.162.7     p54.162.8     p54.162.9  ...  \\\n",
            "0  2.502537e+06  2.531111e+06  2.522721e+06  2.514330e+06  2.505940e+06  ...   \n",
            "1  2.482535e+06  2.533465e+06  2.525088e+06  2.516716e+06  2.508339e+06  ...   \n",
            "2  2.482535e+06  2.529801e+06  2.521496e+06  2.513187e+06  2.504882e+06  ...   \n",
            "3  2.502732e+06  2.530569e+06  2.502431e+06  2.514127e+06  2.505904e+06  ...   \n",
            "4  2.497861e+06  2.525621e+06  2.517421e+06  2.509215e+06  2.501015e+06  ...   \n",
            "\n",
            "    v100.17   v100.18   v100.19   v100.20   v100.21   v100.22   v100.23  \\\n",
            "0 -0.450284 -4.407196 -0.180619 -4.131295 -4.669626 -4.528932 -4.388736   \n",
            "1 -3.257192 -3.115998 -2.975304 -2.834609 -3.396390 -3.254198 -3.112506   \n",
            "2 -0.450284 -1.138290 -0.180619 -0.822476 -1.459094 -1.302933 -1.147271   \n",
            "3  1.370265  1.485515  1.600765  1.716015  1.210612  1.319376  1.428140   \n",
            "4 -0.450284 -0.387420  2.193977  2.278793  1.873673  1.953000  2.031829   \n",
            "\n",
            "    v100.24   v100.25            datetime  \n",
            "0 -4.248540 -4.107846 2005-01-02 18:00:00  \n",
            "1 -2.970314 -0.261194 2005-01-03 00:00:00  \n",
            "2 -0.991110 -0.834949 2005-01-03 06:00:00  \n",
            "3  1.536405  1.645169 2005-01-03 12:00:00  \n",
            "4  2.111157  2.189986 2005-01-03 18:00:00  \n",
            "\n",
            "[5 rows x 552 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 'X' contains features and 'y' contains the target variable\n",
        "X = df.drop(columns=['energy'])  # Features\n",
        "y = df['energy']  # Target variable\n",
        "\n",
        "# Define the cutoff year for the test set (e.g., most recent year)\n",
        "cutoff = pd.to_datetime('2009-01-01 00:00')\n",
        "\n",
        "# Filter data based on 'year' for training and test sets\n",
        "X_train = X[df['datetime'] < cutoff]\n",
        "y_train = y[df['datetime'] < cutoff]\n",
        "X_test = X[df['datetime'] >= cutoff]\n",
        "y_test = y[df['datetime'] >= cutoff]\n",
        "\n",
        "# Verify the shapes or time periods covered in the sets\n",
        "print(\"Training set period:\", X_train['datetime'].min(), \"-\", X_train['datetime'].max())  # Just for verification\n",
        "print(\"Test set period:\", X_test['datetime'].min(), \"-\", X_test['datetime'].max())  # Just for verification\n",
        "print(\"Train set shape:\", X_train.shape, y_train.shape)\n",
        "print(\"Test set shape:\", X_test.shape, y_test.shape)\n",
        "\n",
        "# Drop the 'datetime' column from X_train and X_test\n",
        "X_train = X_train.drop(columns=['datetime'])\n",
        "X_test = X_test.drop(columns=['datetime'])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lbWIPB8e9xlu",
        "outputId": "07099e49-3ac4-46c9-ff17-a4ba5da24fc8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training set period: 2005-01-02 18:00:00 - 2008-02-25 18:00:00\n",
            "Test set period: 2009-03-05 12:00:00 - 2009-12-31 18:00:00\n",
            "Train set shape: (3827, 551) (3827,)\n",
            "Test set shape: (921, 551) (921,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "For this regression problem (energy prediction), metrics like Mean Absolute Error (MAE) or Mean Squared Error (MSE) can be suitable for assessing model performance"
      ],
      "metadata": {
        "id": "RX8Wr8ARsmdJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4. Default Hyper Parameters"
      ],
      "metadata": {
        "id": "puavSoqLtQWJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Using default hyper-parameters, we evaluate Trees and KNN on the testing partition.\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "4V2H6-BULmwN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Decision Trees*"
      ],
      "metadata": {
        "id": "20YUwnuqLKsG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import tree\n",
        "from sklearn import metrics\n",
        "\n",
        "# Initialize Decision Tree Regressor\n",
        "tree_regressor = tree.DecisionTreeRegressor(random_state=0)\n",
        "\n",
        "# Fit the model on the training data\n",
        "tree_regressor.fit(X_train, y_train)\n",
        "\n",
        "# Predict on the test set\n",
        "tree_predictions = tree_regressor.predict(X_test)\n",
        "\n",
        "# Evaluate Decision Tree performance using Mean Squared Error (MSE)\n",
        "tree_mse = (metrics.mean_squared_error(y_test, tree_predictions))\n",
        "print(\"Decision Tree MSE:\", tree_mse)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dAdQYpkbut0N",
        "outputId": "c71701e2-9ca6-4ebc-c8f0-88328fa53b8e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decision Tree MSE: 279096.0921464712\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*KNN*"
      ],
      "metadata": {
        "id": "eeY61HqrLZaw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "# Initialize KNN model\n",
        "knn_model = KNeighborsRegressor()\n",
        "\n",
        "# Create pipelines for scaling methods (StandardScaler and MinMaxScaler)\n",
        "scalers = [('StandardScaler', StandardScaler()), ('MinMaxScaler', MinMaxScaler())]\n",
        "\n",
        "# Evaluate KNN with different scaling methods\n",
        "for scaler_name, scaler in scalers:\n",
        "    # Create pipeline with scaler and KNN model\n",
        "    knn_pipeline = Pipeline([('scaler', scaler), ('knn', knn_model)])\n",
        "\n",
        "    # Fit the pipeline on the training data\n",
        "    knn_pipeline.fit(X_train, y_train)\n",
        "\n",
        "    # Predict on the test set\n",
        "    knn_predictions = knn_pipeline.predict(X_test)\n",
        "\n",
        "    # Evaluate KNN performance (e.g., using Mean Squared Error)\n",
        "    knn_mse = mean_squared_error(y_test, knn_predictions)\n",
        "    print(f\"KNN with {scaler_name} MSE:\", knn_mse)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pgA68QCmwZZA",
        "outputId": "e2cadb5f-178a-4945-d887-ecb0df683230"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "KNN with StandardScaler MSE: 204958.38570563303\n",
            "KNN with MinMaxScaler MSE: 233285.20356867753\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 5. HPO"
      ],
      "metadata": {
        "id": "qPhjZ0daLLpe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, we do hyper-parameter tuning (HPO) for trees and KNN, for the search method we use the Grid and Random search"
      ],
      "metadata": {
        "id": "GMTznq8qMLvj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Grid search for trees*"
      ],
      "metadata": {
        "id": "1M2QeKqkVA7Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "# Define hyperparameters to tune for Decision Tree\n",
        "tree_param_grid = {\n",
        "    'max_depth': [None, 10, 20, 30],\n",
        "    'min_samples_split': [2, 5, 10]\n",
        "}\n",
        "\n",
        "# Initialize Grid Search with the Decision Tree model and parameter grid\n",
        "tree_grid_search = GridSearchCV(DecisionTreeRegressor(random_state=0), tree_param_grid, cv=5, scoring='neg_mean_squared_error')\n",
        "tree_grid_search.fit(X_train, y_train)\n",
        "\n",
        "# Get the best hyperparameters and the corresponding MSE\n",
        "best_tree_params = tree_grid_search.best_params_\n",
        "best_tree_mse = -tree_grid_search.best_score_\n",
        "\n",
        "print(\"Best Decision Tree Hyperparameters:\", best_tree_params)\n",
        "print(\"Best Decision Tree MSE:\", best_tree_mse)\n",
        "\n",
        "\n",
        "# Predict on the test set using the best tree model obtained from grid search\n",
        "best_tree_model = tree_grid_search.best_estimator_\n",
        "y_pred_test = best_tree_model.predict(X_test)\n",
        "\n",
        "# Calculate the mean squared error on the test set\n",
        "test_mse = mean_squared_error(y_test, y_pred_test)\n",
        "print(\"Decision Tree MSE on Test Set:\", test_mse)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zYUMwehOLQyU",
        "outputId": "54d7f83b-3ada-431b-d1e9-3179d95dc9ba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Decision Tree Hyperparameters: {'max_depth': 10, 'min_samples_split': 10}\n",
            "Best Decision Tree MSE: 220582.52402876574\n",
            "Decision Tree MSE on Test Set: 237842.5910418732\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Grid Search for KNN*"
      ],
      "metadata": {
        "id": "nzz1muTTMyz_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "# Create KNN model\n",
        "knn_model = KNeighborsRegressor()\n",
        "\n",
        "# Create pipeline with scaler and KNN model for grid search\n",
        "knn_pipeline = Pipeline([('scaler', StandardScaler()), ('knn', knn_model)])\n",
        "\n",
        "# Define hyperparameters to tune for KNN within the pipeline\n",
        "knn_param_grid = {\n",
        "    'scaler': [StandardScaler(), MinMaxScaler()],  # Test different scalers\n",
        "    'knn__n_neighbors': range(2,16,2),  # Example hyperparameter for KNN\n",
        "    # Other hyperparameters for KNN...\n",
        "}\n",
        "\n",
        "# Initialize Grid Search with the KNN pipeline and parameter grid\n",
        "knn_grid_search = GridSearchCV(knn_pipeline, knn_param_grid, cv=5, scoring='neg_mean_squared_error')\n",
        "knn_grid_search.fit(X_train, y_train)\n",
        "\n",
        "# Get the best hyperparameters and the corresponding MSE\n",
        "best_knn_params = knn_grid_search.best_params_\n",
        "best_knn_mse = -knn_grid_search.best_score_\n",
        "\n",
        "print(\"Best KNN Hyperparameters:\", best_knn_params)\n",
        "print(\"Best KNN MSE:\", best_knn_mse)\n",
        "\n",
        "\n",
        "\n",
        "# Predict on the test set using the best KNN model obtained from grid search\n",
        "best_knn_model = knn_grid_search.best_estimator_\n",
        "y_pred_test_knn = best_knn_model.predict(X_test)\n",
        "\n",
        "# Calculate the mean squared error on the test set\n",
        "test_mse_knn = mean_squared_error(y_test, y_pred_test_knn)\n",
        "print(\"KNN MSE on Test Set:\", test_mse_knn)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qws13DK6dIOu",
        "outputId": "db86bcf0-da81-44e7-c0cc-e5b19790f138"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best KNN Hyperparameters: {'knn__n_neighbors': 14, 'scaler': StandardScaler()}\n",
            "Best KNN MSE: 188706.2455534932\n",
            "KNN MSE on Test Set: 196662.78416797734\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Random Search for Trees*"
      ],
      "metadata": {
        "id": "2i5H6jnfM47k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from scipy.stats import randint\n",
        "\n",
        "# Define hyperparameters to tune for Decision Tree\n",
        "tree_param_dist = {\n",
        "    'max_depth': randint(1, 31),  # Example range for max_depth using sp_randint\n",
        "    'min_samples_split': randint(2, 11)  # Example range for min_samples_split using sp_randint\n",
        "    # Add other hyperparameters for Decision Tree here...\n",
        "}\n",
        "\n",
        "# Initialize Randomized Search with the Decision Tree model and parameter distribution\n",
        "tree_random_search = RandomizedSearchCV(DecisionTreeRegressor(random_state=0), tree_param_dist, n_iter=10, cv=5, scoring='neg_mean_squared_error', random_state=42)\n",
        "tree_random_search.fit(X_train, y_train)\n",
        "\n",
        "# Get the best hyperparameters and the corresponding MSE\n",
        "best_tree_params = tree_random_search.best_params_\n",
        "best_tree_mse = -tree_random_search.best_score_\n",
        "\n",
        "print(\"Best Decision Tree Hyperparameters:\", best_tree_params)\n",
        "print(\"Best Decision Tree MSE:\", best_tree_mse)\n",
        "\n",
        "# Predict on the test set using the best Decision Tree model obtained from random search\n",
        "best_tree_model = tree_random_search.best_estimator_\n",
        "y_pred_test_tree = best_tree_model.predict(X_test)\n",
        "\n",
        "# Calculate the mean squared error on the test set\n",
        "test_mse_tree = mean_squared_error(y_test, y_pred_test_tree)\n",
        "print(\"Decision Tree MSE on Test Set:\", test_mse_tree)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VdaW4P9YVek1",
        "outputId": "ca35fa0a-261a-4b01-fdbe-0d4a639ed726"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Decision Tree Hyperparameters: {'max_depth': 7, 'min_samples_split': 4}\n",
            "Best Decision Tree MSE: 198685.40847071083\n",
            "Decision Tree MSE on Test Set: 219156.9537641815\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Random Search for KNN*"
      ],
      "metadata": {
        "id": "X6z0Bzd7M_gY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from scipy.stats import randint\n",
        "\n",
        "# Create KNN model\n",
        "knn_model = KNeighborsRegressor()\n",
        "\n",
        "# Create pipeline with scaler and KNN model for random search\n",
        "knn_pipeline = Pipeline([('scaler', StandardScaler()), ('knn', knn_model)])\n",
        "\n",
        "# Define hyperparameters to tune for KNN within the pipeline\n",
        "knn_param_dist = {\n",
        "    'scaler': [StandardScaler(), MinMaxScaler()],  # Test different scalers\n",
        "    'knn__n_neighbors': randint(2, 16)  # Example hyperparameter for KNN\n",
        "    # Other hyperparameters for KNN...\n",
        "}\n",
        "\n",
        "# Initialize Randomized Search with the KNN pipeline and parameter distribution\n",
        "knn_random_search = RandomizedSearchCV(knn_pipeline, knn_param_dist, n_iter=10, cv=5, scoring='neg_mean_squared_error', random_state=42)\n",
        "knn_random_search.fit(X_train, y_train)\n",
        "\n",
        "# Get the best hyperparameters and the corresponding MSE\n",
        "best_knn_params = knn_random_search.best_params_\n",
        "best_knn_mse = -knn_random_search.best_score_\n",
        "\n",
        "print(\"Best KNN Hyperparameters:\", best_knn_params)\n",
        "print(\"Best KNN MSE:\", best_knn_mse)\n",
        "\n",
        "# Predict on the test set using the best KNN model obtained from random search\n",
        "best_knn_model = knn_random_search.best_estimator_\n",
        "y_pred_test_knn = best_knn_model.predict(X_test)\n",
        "\n",
        "# Calculate the mean squared error on the test set\n",
        "test_mse_knn = mean_squared_error(y_test, y_pred_test_knn)\n",
        "print(\"KNN MSE on Test Set:\", test_mse_knn)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bfFOjS1CVhai",
        "outputId": "09a8bd6a-eb14-4e7a-fcf6-a58f66f5ce7b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best KNN Hyperparameters: {'knn__n_neighbors': 14, 'scaler': StandardScaler()}\n",
            "Best KNN MSE: 188706.2455534932\n",
            "KNN MSE on Test Set: 196662.78416797734\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The summary of the models so far is:\n"
      ],
      "metadata": {
        "id": "84do4CFyn1Yq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "|                 | Decision Trees | KNN |\n",
        "|-----------------|----------------|-----|\n",
        "| **Default**     | 279096.09 | 204958.38|\n",
        "| **Grid Search** |  237842.59  | 196662.78 |\n",
        "| **Random Search**|     219156.95 |  196662.78 |"
      ],
      "metadata": {
        "id": "SGFSCBf4k-0c"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The best model so far is a KNN with 14 neighbors and StandarScaler, obtained twice from both the Grid and Random search methods.\n"
      ],
      "metadata": {
        "id": "iQbsGfZVn8BB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "**FINE TUNING KNN**"
      ],
      "metadata": {
        "id": "4TdfJ5Oonzly"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In addition to the models proposed in the assigment, we will be trying to perform a Fine Tunning KNN, as a further step in the HPO for the best model we obtained, this is, the StandardScaler KNN."
      ],
      "metadata": {
        "id": "8_O2fFEpq60l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "# Define hyperparameters to fine-tune for KNN\n",
        "knn_param_grid_fine_tune = {\n",
        "    'scaler': [StandardScaler()],\n",
        "    'knn__n_neighbors': range(12, 18),  # Narrow the range around the best value\n",
        "    'knn__weights': ['uniform', 'distance'],  # Try different weighting schemes\n",
        "    'knn__p': [1, 2]  # Consider using different distance measures\n",
        "}\n",
        "\n",
        "# Initialize Grid Search for finer hyperparameter tuning\n",
        "knn_grid_search_fine_tune = GridSearchCV(\n",
        "    knn_pipeline,\n",
        "    knn_param_grid_fine_tune,\n",
        "    cv=5,\n",
        "    scoring='neg_mean_squared_error'\n",
        ")\n",
        "knn_grid_search_fine_tune.fit(X_train, y_train)\n",
        "\n",
        "# Get the best hyperparameters and corresponding MSE\n",
        "best_knn_params_fine_tune = knn_grid_search_fine_tune.best_params_\n",
        "best_knn_mse_fine_tune = -knn_grid_search_fine_tune.best_score_\n",
        "\n",
        "print(\"Best KNN Hyperparameters (Fine-tuned):\", best_knn_params_fine_tune)\n",
        "print(\"Best KNN MSE (Fine-tuned):\", best_knn_mse_fine_tune)\n",
        "\n",
        "# Predict on the test set using the best KNN model from fine-tuned search\n",
        "best_knn_model_fine_tune = knn_grid_search_fine_tune.best_estimator_\n",
        "y_pred_test_knn_fine_tune = best_knn_model_fine_tune.predict(X_test)\n",
        "\n",
        "# Calculate the mean squared error on the test set\n",
        "test_mse_knn_fine_tune = mean_squared_error(y_test, y_pred_test_knn_fine_tune)\n",
        "print(\"KNN MSE on Test Set (Fine-tuned):\", test_mse_knn_fine_tune)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HkuJ3H2VeS9w",
        "outputId": "dd9c9e3b-1272-4cc6-8d6c-60645873986d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best KNN Hyperparameters (Fine-tuned): {'knn__n_neighbors': 16, 'knn__p': 1, 'knn__weights': 'distance', 'scaler': StandardScaler()}\n",
            "Best KNN MSE (Fine-tuned): 173467.7712369944\n",
            "KNN MSE on Test Set (Fine-tuned): 177394.30447103587\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We see how the MSE improves in the fine-tunned model by more than 10%, so the additional computational cost pays off."
      ],
      "metadata": {
        "id": "yDPkFZj4sJpx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 6. Using the best method of the ones evaluated previously:\n",
        "\n",
        "1.   Final model: using the best method, train the final model and use it to make predictions on the competition dataset. Save both the final model and the competition predictions on files.\n",
        "\n",
        "\n",
        "We first upload the competition data the same way we uploaded the give data."
      ],
      "metadata": {
        "id": "vRZyW7eUNqtp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "uploaded_comp = files.upload()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "outputId": "0a6065b8-5a67-4c24-e13e-91c96759da9e",
        "id": "E1XPhMevpuKD"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-be9fcbab-6532-46d8-9835-c8492528481c\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-be9fcbab-6532-46d8-9835-c8492528481c\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving wind_competition.csv.gzip to wind_competition.csv.gzip\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_comp = pd.read_csv('wind_competition.csv.gzip', compression=\"gzip\")"
      ],
      "metadata": {
        "id": "0WHFYqxSpuKF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "And now, the same preprocessing done to the train and test sets\n",
        "must be performed."
      ],
      "metadata": {
        "id": "tApuFg91yzfW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Missing values\n",
        "\n",
        "#Calculate the percentage of missing values for each column\n",
        "missing_percentage_comp = (df_comp.isnull().sum() / len(df)) * 100\n",
        "\n",
        "# Sort columns by their missing percentage in descending order\n",
        "missing_percentage_comp = missing_percentage_comp.sort_values(ascending=False)\n",
        "\n",
        "# Display the result\n",
        "print(missing_percentage_comp)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ElxqW-NHrhGm",
        "outputId": "794dc6b2-ac7d-42dd-f4ad-f9a2d9f2dc33"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "stl3.11    5.412805\n",
            "fsr.22     5.370682\n",
            "stl3.1     5.328559\n",
            "v10n.10    5.286436\n",
            "u10n.7     5.223252\n",
            "             ...   \n",
            "iews.2     1.074136\n",
            "month      0.000000\n",
            "hour       0.000000\n",
            "day        0.000000\n",
            "year       0.000000\n",
            "Length: 554, dtype: float64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Imputation\n",
        "# Select numerical columns\n",
        "numeric_columns = df_comp.select_dtypes(include=['float64', 'int64']).columns\n",
        "\n",
        "# Impute missing values with the median for numerical columns\n",
        "for column in numeric_columns:\n",
        "    median_value = df_comp[column].median()\n",
        "    df_comp[column].fillna(median_value, inplace=True)\n"
      ],
      "metadata": {
        "id": "rKxS-1iouthU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check for missing values after imputation\n",
        "missing_after_imputation = df_comp.isnull().sum()\n",
        "print(\"Missing values after imputation:\")\n",
        "print(missing_after_imputation)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1787714e-b5d0-42c9-b497-a265d1e7d053",
        "id": "Vih71gO7uthV"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Missing values after imputation:\n",
            "year         0\n",
            "month        0\n",
            "day          0\n",
            "hour         0\n",
            "p54.162.1    0\n",
            "            ..\n",
            "v100.21      0\n",
            "v100.22      0\n",
            "v100.23      0\n",
            "v100.24      0\n",
            "v100.25      0\n",
            "Length: 554, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Drop unused variables\n",
        "df_comp = df_comp.drop(['year', 'month', 'day', 'hour'], axis=1)\n",
        "\n",
        "print(df_comp.head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3890cb96-e9c8-4921-8c99-b850bff10a1c",
        "id": "_wnj6yu0W05B"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      p54.162.1     p54.162.2     p54.162.3     p54.162.4     p54.162.5  \\\n",
            "0  2.403131e+06  2.395445e+06  2.387755e+06  2.380065e+06  2.372380e+06   \n",
            "1  2.410306e+06  2.402394e+06  2.480434e+06  2.386571e+06  2.378660e+06   \n",
            "2  2.434908e+06  2.426793e+06  2.418683e+06  2.410573e+06  2.402462e+06   \n",
            "3  2.447112e+06  2.487275e+06  2.431027e+06  2.422984e+06  2.414942e+06   \n",
            "4  2.459695e+06  2.487275e+06  2.443809e+06  2.435866e+06  2.465786e+06   \n",
            "\n",
            "      p54.162.6     p54.162.7     p54.162.8     p54.162.9    p54.162.10  ...  \\\n",
            "0  2.399548e+06  2.391582e+06  2.383621e+06  2.375660e+06  2.367699e+06  ...   \n",
            "1  2.493774e+06  2.398599e+06  2.477355e+06  2.382225e+06  2.374038e+06  ...   \n",
            "2  2.431465e+06  2.423075e+06  2.414689e+06  2.469211e+06  2.397912e+06  ...   \n",
            "3  2.443696e+06  2.435378e+06  2.427060e+06  2.418742e+06  2.410423e+06  ...   \n",
            "4  2.456252e+06  2.448034e+06  2.439815e+06  2.431596e+06  2.423377e+06  ...   \n",
            "\n",
            "    v100.16   v100.17   v100.18   v100.19   v100.20   v100.21   v100.22  \\\n",
            "0  7.212586  7.057422  6.901760 -1.429159  6.591434  7.184147  7.030980   \n",
            "1  0.207289  0.583972 -1.553888 -1.429159  1.714518  0.345988  0.723170   \n",
            "2  1.670114  1.691568  1.712522  1.733976 -1.278985  1.664127  1.682587   \n",
            "3  1.217597  1.278464  1.339332  1.399701  1.460569  1.215102  1.272477   \n",
            "4  3.755089  3.686738 -1.553888  3.549536  3.481184  3.781532  3.710686   \n",
            "\n",
            "    v100.23   v100.24   v100.25  \n",
            "0  6.877313  6.723647  6.570479  \n",
            "1  1.100850  1.478031  1.855712  \n",
            "2  1.700548 -1.457099  1.736470  \n",
            "3  1.329853 -1.457099  1.444105  \n",
            "4 -1.530439  3.569492  3.498646  \n",
            "\n",
            "[5 rows x 550 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check for constant columns\n",
        "constant_columns = [col for col in df_comp.columns if df_comp[col].nunique() == 1]\n",
        "\n",
        "# Display constant columns\n",
        "print(\"Constant columns:\")\n",
        "print(constant_columns)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ff1536f6-983b-4e47-ee9f-394548e39f90",
        "id": "LGP-m_Dyjmd8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Constant columns:\n",
            "[]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Lets make the predictions on the competition data using the best method and save the model and the results"
      ],
      "metadata": {
        "id": "U9pLfEDqu_KL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from joblib import dump\n",
        "import pandas as pd\n",
        "\n",
        "#drop datetime fromm X\n",
        "X = X.drop(columns=['datetime'])\n",
        "\n",
        "# Define the best hyperparameters obtained from fine-tuning\n",
        "best_knn_params = {\n",
        "    'n_neighbors': 16,\n",
        "    'p': 1,\n",
        "    'weights': 'distance'\n",
        "}\n",
        "\n",
        "# Create the final model with the best parameters\n",
        "final_model = KNeighborsRegressor(**best_knn_params)\n",
        "\n",
        "# Apply StandardScaler to the entire available dataset\n",
        "scaler = StandardScaler()\n",
        "X_available_scaled = scaler.fit_transform(X)\n",
        "\n",
        "# Train the final KNN model on the entire available dataset (train + validation sets)\n",
        "final_model.fit(X_available_scaled, y)\n",
        "\n",
        "# Save the final KNN model to a file\n",
        "dump(final_model, 'final_knn_model_fine_tuned.joblib')\n",
        "\n",
        "# Make predictions on the competition dataset using the trained model and scaler\n",
        "X_competition_scaled = scaler.transform(df_comp)  # Scale the competition dataset\n",
        "competition_predictions_knn = final_model.predict(X_competition_scaled)\n",
        "\n",
        "# Save the competition predictions to a CSV file\n",
        "competition_predictions_df_knn = pd.DataFrame({'Predictions': competition_predictions_knn})\n",
        "competition_predictions_df_knn.to_csv('competition_predictions_knn_fine_tuned.csv', index=False)\n"
      ],
      "metadata": {
        "id": "zFdLf1ski1sr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "To download files"
      ],
      "metadata": {
        "id": "fZFaUaPmBo8e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "\n",
        "# Download the model file\n",
        "files.download('final_knn_model_fine_tuned.joblib')\n",
        "\n",
        "# Download the predictions file\n",
        "files.download('competition_predictions_knn_fine_tuned.csv')\n"
      ],
      "metadata": {
        "id": "QNjB100y9q5p",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "c5a3ffbd-0dfb-4cb6-bceb-7be1936ac66a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_27a97f12-1fd7-466a-8494-0b8c59e5fc82\", \"final_knn_model_fine_tuned.joblib\", 20929844)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_b0182beb-0f2b-4f0e-aeba-1418baaffb82\", \"competition_predictions_knn_fine_tuned.csv\", 21844)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 7. Feature selection for KNN:\n",
        "\n",
        "Now the goal is to take the model given by the HPO for KNN and find the most important features in this model. For this, we will be using the existing model with 14 Neighbors and Standard Scaler and try to find the subset of best features with Grid Search.\n",
        "\n",
        "The criteria used are: f_regression and mutual_info_regression."
      ],
      "metadata": {
        "id": "UE6Ox3wOOBev"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_selection import SelectKBest, f_regression, mutual_info_regression\n",
        "\n",
        "# Define the range of features (k) to test in grid search\n",
        "k_range = [5, 10, 15, 20, 25]\n",
        "feature_names=df.columns.tolist()\n",
        "\n",
        "# Initialize KNN model with the optimal number of neighbors\n",
        "knn_model_with_optimal_neighbors = KNeighborsRegressor(n_neighbors=best_knn_params['knn__n_neighbors'])\n",
        "\n",
        "# Create a new pipeline with feature selection and KNN model\n",
        "feature_selection_knn_pipeline = Pipeline([\n",
        "    ('scaler', StandardScaler()),\n",
        "    ('feature_selection', SelectKBest(score_func=f_regression)),  # Use f_regression as the initial criterion\n",
        "    ('knn', knn_model_with_optimal_neighbors)\n",
        "])\n",
        "\n",
        "# Define hyperparameters to tune for feature selection and KNN\n",
        "feature_selection_param_grid = {\n",
        "    'feature_selection__k': k_range,  # Test different values of k (number of features)\n",
        "    'feature_selection__score_func': [f_regression, mutual_info_regression]  # Test different feature selection criteria\n",
        "    # Other hyperparameters for KNN...\n",
        "}\n",
        "\n",
        "# Initialize Grid Search with the feature selection and KNN pipeline and parameter grid\n",
        "feature_selection_grid_search = GridSearchCV(feature_selection_knn_pipeline, feature_selection_param_grid, cv=5, scoring='neg_mean_squared_error')\n",
        "feature_selection_grid_search.fit(X_train, y_train)\n",
        "\n",
        "# Get the best hyperparameters and the corresponding MSE\n",
        "best_feature_selection_params = feature_selection_grid_search.best_params_\n",
        "best_feature_selection_mse = -feature_selection_grid_search.best_score_\n",
        "\n",
        "print(\"Best Feature Selection Hyperparameters:\", best_feature_selection_params)\n",
        "print(\"Best Feature Selection MSE:\", best_feature_selection_mse)\n",
        "\n",
        "# Get the optimal number of features and the corresponding selected features\n",
        "optimal_num_features = best_feature_selection_params['feature_selection__k']\n",
        "selected_features = feature_selection_grid_search.best_estimator_.named_steps['feature_selection'].get_support()\n",
        "\n",
        "# Print the results\n",
        "print(\"Optimal Number of Features:\", optimal_num_features)\n",
        "selected_feature_names = [feature_names[i] for i, selected in enumerate(selected_features) if selected]\n",
        "print(\"Selected Feature Names:\", selected_feature_names)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aX5cwoYiuYuV",
        "outputId": "ac32d0a5-cf58-47fe-8292-6304cfa31e29"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Feature Selection Hyperparameters: {'feature_selection__k': 5, 'feature_selection__score_func': <function mutual_info_regression at 0x7a3cf9da16c0>}\n",
            "Best Feature Selection MSE: 197038.5706384718\n",
            "Optimal Number of Features: 5\n",
            "Selected Feature Names: ['iews.5', 'iews.12', 'iews.13', 'iews.17', 'u100.10']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Feature selection with Fine tuning model**"
      ],
      "metadata": {
        "id": "EKXl04ZS9gYo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_selection import SelectKBest, f_regression, mutual_info_regression\n",
        "\n",
        "# Define the range of features (k) to test in feature selection\n",
        "k_range = [5, 10, 15, 20, 25]\n",
        "feature_names = df.columns.tolist()\n",
        "\n",
        "# Initialize KNN model with the best hyperparameters\n",
        "knn_model_fine_tuned = KNeighborsRegressor(n_neighbors=16, p=1, weights='distance')\n",
        "\n",
        "# Create a new pipeline with feature selection and KNN model\n",
        "feature_selection_knn_pipeline = Pipeline([\n",
        "    ('scaler', StandardScaler()),\n",
        "    ('feature_selection', SelectKBest(score_func=f_regression)),\n",
        "    ('knn', knn_model_fine_tuned)\n",
        "])\n",
        "\n",
        "# Define hyperparameters to tune for feature selection\n",
        "feature_selection_param_grid = {\n",
        "    'feature_selection__k': k_range,\n",
        "    'feature_selection__score_func': [f_regression, mutual_info_regression]\n",
        "    # Other hyperparameters for KNN can be added here if necessary\n",
        "}\n",
        "\n",
        "# Initialize Grid Search with the feature selection and KNN pipeline and parameter grid\n",
        "feature_selection_grid_search = GridSearchCV(\n",
        "    feature_selection_knn_pipeline,\n",
        "    feature_selection_param_grid,\n",
        "    cv=5,\n",
        "    scoring='neg_mean_squared_error'\n",
        ")\n",
        "feature_selection_grid_search.fit(X_train, y_train)\n",
        "\n",
        "# Get the best hyperparameters and the corresponding MSE\n",
        "best_feature_selection_params = feature_selection_grid_search.best_params_\n",
        "best_feature_selection_mse = -feature_selection_grid_search.best_score_\n",
        "\n",
        "print(\"Best Feature Selection Hyperparameters:\", best_feature_selection_params)\n",
        "print(\"Best Feature Selection MSE:\", best_feature_selection_mse)\n",
        "\n",
        "# Get the optimal number of features and the corresponding selected features\n",
        "optimal_num_features = best_feature_selection_params['feature_selection__k']\n",
        "selected_features = feature_selection_grid_search.best_estimator_.named_steps['feature_selection'].get_support()\n",
        "\n",
        "# Print the results\n",
        "print(\"Optimal Number of Features:\", optimal_num_features)\n",
        "selected_feature_names = [feature_names[i] for i, selected in enumerate(selected_features) if selected]\n",
        "print(\"Selected Feature Names:\", selected_feature_names)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tIFs1rRq7Ztc",
        "outputId": "3eb1ea50-e513-4d90-8cef-7aa2d4e59d2a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Feature Selection Hyperparameters: {'feature_selection__k': 25, 'feature_selection__score_func': <function mutual_info_regression at 0x7dde07279360>}\n",
            "Best Feature Selection MSE: 191673.4369844064\n",
            "Optimal Number of Features: 25\n",
            "Selected Feature Names: ['iews.1', 'iews.3', 'iews.5', 'iews.7', 'iews.9', 'iews.10', 'iews.11', 'iews.12', 'iews.13', 'iews.16', 'iews.17', 'iews.18', 'iews.19', 'iews.20', 'iews.22', 'iews.23', 'iews.24', 'u100.3', 'u100.6', 'u100.7', 'u100.10', 'u100.12', 'u100.14', 'u100.21', 'u100.23']\n"
          ]
        }
      ]
    }
  ]
}